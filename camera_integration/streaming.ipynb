{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m     exit()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 10\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: Could not read frame.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Could not read frame.\")\n",
    "        break\n",
    "\n",
    "    # Remove the blue channel\n",
    "    frame[:, :, 0] = 0\n",
    "    frame[:, :, 1] = 0\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Video Stream without Blue Channel', frame)\n",
    "\n",
    "    # Release frame memory\n",
    "    frame = None\n",
    "\n",
    "    # Exit loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 53\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;66;03m# Add a delay to control the frame rate (adjust if needed)\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Release resources\u001b[39;00m\n\u001b[0;32m     56\u001b[0m camera\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "# Open the MP4 video\n",
    "video = cv2.VideoCapture('..\\\\simulations\\\\PEGDA700_starship_rebinned_36degps_intensity11x.mp4')\n",
    "if not video.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Open the USB camera\n",
    "camera = cv2.VideoCapture(0)\n",
    "if not camera.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "    video.release()\n",
    "    exit()\n",
    "\n",
    "# Set resolution for both sources to match (adjust as needed)\n",
    "#camera.set(cv2.CAP_PROP_FRAME_WIDTH, 320)\n",
    "#camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 240)\n",
    "#video.set(cv2.CAP_PROP_FRAME_WIDTH, 320)\n",
    "#video.set(cv2.CAP_PROP_FRAME_HEIGHT, 240)\n",
    "\n",
    "while True:\n",
    "    # Read frame from camera\n",
    "    ret_camera, frame_camera = camera.read()\n",
    "    if not ret_camera:\n",
    "        print(\"Error: Could not read frame from camera.\")\n",
    "        break\n",
    "\n",
    "    # Read frame from video\n",
    "    ret_video, frame_video = video.read()\n",
    "    if not ret_video:\n",
    "        print(\"End of video reached or error reading frame.\")\n",
    "        break\n",
    "\n",
    "    # Resize video frame to match camera frame dimensions\n",
    "    frame_video = cv2.resize(frame_video, (frame_camera.shape[1], frame_camera.shape[0]))\n",
    "        # Remove the blue channel\n",
    "    frame_camera[:, :, 0] = 0\n",
    "    frame_camera[:, :, 1] = 0\n",
    "\n",
    "    # Concatenate the frames side-by-side\n",
    "    combined_frame = cv2.hconcat([frame_camera, frame_video])\n",
    "\n",
    "    # Display the combined frame\n",
    "    cv2.imshow('Camera vs. Video Comparison', combined_frame)\n",
    "\n",
    "    # Exit the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    # Add a delay to control the frame rate (adjust if needed)\n",
    "    time.sleep(0.05)\n",
    "\n",
    "# Release resources\n",
    "camera.release()\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of video reached or error reading frame.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "# Open the MP4 video\n",
    "video = cv2.VideoCapture('..\\\\simulations\\\\PEGDA700_starship_rebinned_36degps_intensity11x.mp4')\n",
    "if not video.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Open the USB camera\n",
    "camera = cv2.VideoCapture(0)\n",
    "if not camera.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "    video.release()\n",
    "    exit()\n",
    "\n",
    "def resize_with_aspect_ratio(image, target_width, target_height):\n",
    "    h, w = image.shape[:2]\n",
    "    aspect = w / h\n",
    "    \n",
    "    if aspect > target_width / target_height:\n",
    "        new_w = target_width\n",
    "        new_h = int(new_w / aspect)\n",
    "    else:\n",
    "        new_h = target_height\n",
    "        new_w = int(new_h * aspect)\n",
    "    \n",
    "    resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Create a black canvas of target size\n",
    "    canvas = np.zeros((target_height, target_width, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Calculate position to paste the resized image\n",
    "    y_offset = (target_height - new_h) // 2\n",
    "    x_offset = (target_width - new_w) // 2\n",
    "    \n",
    "    # Paste the resized image onto the canvas\n",
    "    canvas[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = resized\n",
    "    \n",
    "    return canvas\n",
    "\n",
    "while True:\n",
    "    # Read frame from camera\n",
    "    ret_camera, frame_camera = camera.read()\n",
    "    if not ret_camera:\n",
    "        print(\"Error: Could not read frame from camera.\")\n",
    "        break\n",
    "\n",
    "    # Read frame from video\n",
    "    ret_video, frame_video = video.read()\n",
    "    if not ret_video:\n",
    "        print(\"End of video reached or error reading frame.\")\n",
    "        break\n",
    "\n",
    "    # Resize video frame to match camera frame dimensions while maintaining aspect ratio\n",
    "    frame_video = resize_with_aspect_ratio(frame_video, frame_camera.shape[1], frame_camera.shape[0])\n",
    "\n",
    "    # Remove the blue channel from camera frame\n",
    "    frame_camera[:, :, 0] = 0\n",
    "    frame_camera[:, :, 1] = 0\n",
    "\n",
    "    # Concatenate the frames side-by-side\n",
    "    combined_frame = cv2.hconcat([frame_camera, frame_video])\n",
    "\n",
    "    # Display the combined frame\n",
    "    cv2.imshow('Camera vs. Video Comparison', combined_frame)\n",
    "\n",
    "    # Exit the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    # Add a delay to control the frame rate (adjust if needed)\n",
    "    time.sleep(0.05)\n",
    "\n",
    "# Release resources\n",
    "camera.release()\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 85\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# Add a delay to control the frame rate (adjust if needed)\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Release resources\u001b[39;00m\n\u001b[0;32m     88\u001b[0m camera\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Open the MP4 video\n",
    "video = cv2.VideoCapture('..\\\\simulations\\\\PEGDA700_starship_rebinned_36degps_intensity11x.mp4')\n",
    "if not video.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Open the USB camera\n",
    "camera = cv2.VideoCapture(0)\n",
    "if not camera.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "    video.release()\n",
    "    exit()\n",
    "\n",
    "def resize_with_aspect_ratio(image, target_width, target_height):\n",
    "    h, w = image.shape[:2]\n",
    "    aspect = w / h\n",
    "    \n",
    "    if aspect > target_width / target_height:\n",
    "        new_w = target_width\n",
    "        new_h = int(new_w / aspect)\n",
    "    else:\n",
    "        new_h = target_height\n",
    "        new_w = int(new_h * aspect)\n",
    "    \n",
    "    resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Create a black canvas of target size\n",
    "    canvas = np.zeros((target_height, target_width, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Calculate position to paste the resized image\n",
    "    y_offset = (target_height - new_h) // 2\n",
    "    x_offset = (target_width - new_w) // 2\n",
    "    \n",
    "    # Paste the resized image onto the canvas\n",
    "    canvas[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = resized\n",
    "    \n",
    "    return canvas\n",
    "\n",
    "while True:\n",
    "    # Read frame from camera\n",
    "    ret_camera, frame_camera = camera.read()\n",
    "    if not ret_camera:\n",
    "        print(\"Error: Could not read frame from camera.\")\n",
    "        break\n",
    "\n",
    "    # Create red-filtered streaming video\n",
    "    red_filtered_frame = frame_camera.copy()\n",
    "    red_filtered_frame[:, :, 0] = 0  # Set blue channel to 0\n",
    "    red_filtered_frame[:, :, 1] = 0  # Set green channel to 0\n",
    "\n",
    "    # Convert camera frame to grayscale\n",
    "    gray_frame_camera = cv2.cvtColor(frame_camera, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Read frame from video\n",
    "    ret_video, frame_video = video.read()\n",
    "    if not ret_video:\n",
    "        print(\"End of video reached or error reading frame.\")\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, 0)  # Reset video to beginning\n",
    "        continue\n",
    "\n",
    "    # Resize video frame to match camera frame dimensions while maintaining aspect ratio\n",
    "    frame_video = resize_with_aspect_ratio(frame_video, frame_camera.shape[1], frame_camera.shape[0])\n",
    "\n",
    "    # Convert video frame to grayscale\n",
    "    gray_frame_video = cv2.cvtColor(frame_video, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Subtract video from camera frame\n",
    "    difference_frame = cv2.absdiff(gray_frame_camera, gray_frame_video)\n",
    "\n",
    "    # Display the frames in separate windows\n",
    "    cv2.imshow('Original MP4', frame_video)\n",
    "    cv2.imshow('Red-filtered Streaming Video', red_filtered_frame)\n",
    "    cv2.imshow('Grayscale Streaming Video', gray_frame_camera)\n",
    "    cv2.imshow('Grayscale Streaming minus MP4', difference_frame)\n",
    "\n",
    "    # Exit the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    # Add a delay to control the frame rate (adjust if needed)\n",
    "    time.sleep(0.05)\n",
    "\n",
    "# Release resources\n",
    "camera.release()\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 97\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;66;03m# Add a delay to control the frame rate (adjust if needed)\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Release resources\u001b[39;00m\n\u001b[0;32m    100\u001b[0m camera\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Open the MP4 video\n",
    "video = cv2.VideoCapture('..\\\\simulations\\\\PEGDA700_starship_rebinned_36degps_intensity11x.mp4')\n",
    "if not video.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Open the USB camera\n",
    "camera = cv2.VideoCapture(0)\n",
    "if not camera.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "    video.release()\n",
    "    exit()\n",
    "\n",
    "def resize_with_aspect_ratio(image, target_width, target_height):\n",
    "    h, w = image.shape[:2]\n",
    "    aspect = w / h\n",
    "    \n",
    "    if aspect > target_width / target_height:\n",
    "        new_w = target_width\n",
    "        new_h = int(new_w / aspect)\n",
    "    else:\n",
    "        new_h = target_height\n",
    "        new_w = int(new_h * aspect)\n",
    "    \n",
    "    resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Create a black canvas of target size\n",
    "    canvas = np.zeros((target_height, target_width, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Calculate position to paste the resized image\n",
    "    y_offset = (target_height - new_h) // 2\n",
    "    x_offset = (target_width - new_w) // 2\n",
    "    \n",
    "    # Paste the resized image onto the canvas\n",
    "    canvas[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = resized\n",
    "    \n",
    "    return canvas\n",
    "\n",
    "while True:\n",
    "    # Read frame from camera\n",
    "    ret_camera, frame_camera = camera.read()\n",
    "    if not ret_camera:\n",
    "        print(\"Error: Could not read frame from camera.\")\n",
    "        break\n",
    "\n",
    "    # Create red-filtered streaming video\n",
    "    red_filtered_frame = frame_camera.copy()\n",
    "    red_filtered_frame[:, :, 0] = 0  # Set blue channel to 0\n",
    "    red_filtered_frame[:, :, 1] = 0  # Set green channel to 0\n",
    "\n",
    "    # Convert camera frame to grayscale\n",
    "    gray_frame_camera = cv2.cvtColor(frame_camera, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Read frame from video\n",
    "    ret_video, frame_video = video.read()\n",
    "    if not ret_video:\n",
    "        print(\"End of video reached or error reading frame.\")\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, 0)  # Reset video to beginning\n",
    "        continue\n",
    "\n",
    "    # Resize video frame to match camera frame dimensions while maintaining aspect ratio\n",
    "    frame_video = resize_with_aspect_ratio(frame_video, frame_camera.shape[1], frame_camera.shape[0])\n",
    "\n",
    "    # Convert video frame to grayscale\n",
    "    gray_frame_video = cv2.cvtColor(frame_video, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Subtract video from camera frame\n",
    "    difference_frame = cv2.absdiff(gray_frame_camera, gray_frame_video)\n",
    "\n",
    "    # Convert grayscale images to 3-channel for stacking\n",
    "    gray_frame_camera_rgb = cv2.cvtColor(gray_frame_camera, cv2.COLOR_GRAY2BGR)\n",
    "    difference_frame_rgb = cv2.cvtColor(difference_frame, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Stack frames\n",
    "    top_row = np.hstack((frame_video, red_filtered_frame))\n",
    "    bottom_row = np.hstack((gray_frame_camera_rgb, difference_frame_rgb))\n",
    "    combined_grid = np.vstack((top_row, bottom_row))\n",
    "\n",
    "    # Add labels to each quadrant\n",
    "    cv2.putText(combined_grid, \"Original MP4\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "    cv2.putText(combined_grid, \"Red-filtered Streaming\", (frame_video.shape[1] + 10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "    cv2.putText(combined_grid, \"Grayscale Streaming\", (10, frame_video.shape[0] + 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "    cv2.putText(combined_grid, \"Grayscale Difference\", (frame_video.shape[1] + 10, frame_video.shape[0] + 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    # Display the combined grid\n",
    "    cv2.imshow('All Videos', combined_grid)\n",
    "\n",
    "    # Exit the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    # Add a delay to control the frame rate (adjust if needed)\n",
    "    time.sleep(0.05)\n",
    "\n",
    "# Release resources\n",
    "camera.release()\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
